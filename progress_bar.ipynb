{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccf9856b",
   "metadata": {},
   "source": [
    "Just run all these cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e08b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "from einops import einsum\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec2e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89ba94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_tensor = torch.load('/workspace/llm-progress-monitor/qwen3_4b_weight_tensor.pt')\n",
    "model_name = 'Qwen/Qwen3-4B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfff48aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModel(model_name, device_map=device, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f67b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ema_preds(log_preds, alpha=0.99):\n",
    "    given_alpha = alpha\n",
    "    preds_list = log_preds.exp().tolist()\n",
    "    \n",
    "    ema_preds = []\n",
    "    cur_ema = None\n",
    "    for i,pred in enumerate(preds_list):\n",
    "        if pred < 10:\n",
    "            alpha = 0.5\n",
    "        else:\n",
    "            alpha = given_alpha\n",
    "        if cur_ema is None:\n",
    "            cur_ema = pred\n",
    "        else:\n",
    "            cur_ema = alpha*(cur_ema-1) + (1-alpha)*pred #-1 because we have stepped one token\n",
    "        ema_preds.append(cur_ema)\n",
    "    return ema_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2f75a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_preds(activation, weight_tensor):\n",
    "    print(activation.shape, weight_tensor.shape, activation.dtype, weight_tensor.dtype)\n",
    "\n",
    "    return einsum(\n",
    "        einsum(activation, weight_tensor, 'seq d_model, pca d_model -> seq pca').softmax(dim=1),\n",
    "        0.5+torch.arange(weight_tensor.shape[0]).to(device, dtype=torch.bfloat16),\n",
    "        'seq pca, pca -> seq'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d7ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bad3bc7d4154496a62272f231784a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Text Generation Progress</h3>'), Textarea(value='', description='Prompt:', layoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1a7090727743e1aa6939a19a425d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.bfloat16\n",
      "torch.Size([10, 2560]) 2\n",
      "torch.Size([10, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/llm-progress-monitor/venv/lib/python3.11/site-packages/torch/functional.py:422: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:179.)\n",
      "  return _VF.einsum(equation, operands)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.Size([1, 2560]) 2\n",
      "torch.Size([1, 2560]) torch.Size([8, 2560]) torch.bfloat16 torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create input text box for prompt\n",
    "prompt_input = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder='Enter your prompt here...',\n",
    "    description='Prompt:',\n",
    "    layout=widgets.Layout(width='100%', height='80px')\n",
    ")\n",
    "\n",
    "# Create submit button\n",
    "submit_button = widgets.Button(\n",
    "    description='Generate Text',\n",
    "    button_style='success',\n",
    "    tooltip='Click to start text generation',\n",
    "    icon='play'\n",
    ")\n",
    "\n",
    "# Create progress bar widget\n",
    "progress_bar = widgets.FloatProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    description='Progress:',\n",
    "    bar_style='info',\n",
    "    style={'bar_color': '#20B2AA'},\n",
    "    orientation='horizontal'\n",
    ")\n",
    "\n",
    "# Create percentage label\n",
    "percentage_label = widgets.HTML(\n",
    "    value=\"<b>0.0%</b>\",\n",
    "    description='',\n",
    ")\n",
    "\n",
    "# Create horizontal box for progress bar and percentage\n",
    "progress_row = widgets.HBox([progress_bar, percentage_label])\n",
    "\n",
    "# Create text widget for token display\n",
    "token_display = widgets.HTML(\n",
    "    value=\"<b>Generated tokens will appear here...</b>\",\n",
    "    placeholder='',\n",
    "    description='',\n",
    ")\n",
    "\n",
    "# Create container for the widgets\n",
    "progress_container = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Text Generation Progress</h3>\"),\n",
    "    prompt_input,\n",
    "    submit_button,\n",
    "    progress_row,\n",
    "    token_display\n",
    "])\n",
    "\n",
    "# Display the widget\n",
    "display(progress_container)\n",
    "\n",
    "def on_submit_clicked(b):\n",
    "    # Reset progress\n",
    "    progress_bar.value = 0\n",
    "    percentage_label.value = \"<b>0.0%</b>\"\n",
    "    token_display.value = \"<b>Generating...</b>\"\n",
    "    \n",
    "    # Get prompt from input\n",
    "    prompt = prompt_input.value\n",
    "    # Apply chat template\n",
    "    prompt = model.tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": prompt}], tokenize=False, add_generation_prompt=True)\n",
    "    cur_log_preds = []\n",
    "    n_tokens_generated = 0\n",
    "    generated_tokens = []\n",
    "\n",
    "    with model.generate(prompt, max_new_tokens=1000, do_sample=False) as tracer:\n",
    "        # Call .all() to apply intervention to each new token\n",
    "        with tracer.all():\n",
    "            activations = model.model.layers[15].output[0]\n",
    "            print(activations.dtype)\n",
    "            if len(activations.shape) == 1:\n",
    "                activations = activations.unsqueeze(0)\n",
    "            # Pad the last dimension to 2560\n",
    "            if activations.shape[-1] < 2560:\n",
    "                pad_size = 2560 - activations.shape[-1]\n",
    "                activations = torch.nn.functional.pad(activations, (0, pad_size))\n",
    "            print(activations.shape, len(activations.shape))\n",
    "            preds = get_log_preds(activations, weight_tensor).tolist()\n",
    "            if len(preds) > 1:\n",
    "                pass\n",
    "            else:\n",
    "                cur_log_preds+=preds\n",
    "                ema_preds = get_ema_preds(torch.tensor(cur_log_preds))\n",
    "                n_tokens_generated+=1\n",
    "                pred_tokens_remaining = ema_preds[-1]\n",
    "                pred_percent_through = n_tokens_generated/(n_tokens_generated + pred_tokens_remaining)\n",
    "                \n",
    "                token = model.lm_head.output.argmax(dim=-1).tolist()\n",
    "                token_str = model.tokenizer.decode(token[0][0], skip_special_tokens=True)\n",
    "                generated_tokens.append(token_str)\n",
    "                \n",
    "                # Update progress bar\n",
    "                progress_bar.value = pred_percent_through * 100\n",
    "                \n",
    "                # Update percentage label\n",
    "                percentage_label.value = f\"<b>{pred_percent_through*100:.1f}%</b>\"\n",
    "                \n",
    "                # Update token display with all generated tokens\n",
    "                tokens_html = \" \".join([f\"<span style='background-color: #e6f3ff; padding: 2px 4px; margin: 1px; border-radius: 3px;'>{token}</span>\" for token in generated_tokens])\n",
    "                token_display.value = f\"<b>Generated tokens:</b><br>{tokens_html}<br><br><b>Latest:</b> '{token_str}' | <b>Predicted:</b> {pred_percent_through*100:.1f}% through\"\n",
    "\n",
    "# Connect button click to function\n",
    "submit_button.on_click(on_submit_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167849a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1de812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
