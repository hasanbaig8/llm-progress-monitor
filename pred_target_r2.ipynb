{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a639cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1cb29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, activations = torch.load('/workspace/llm-progress-monitor/rollouts-test/activations/0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a12ba4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ce002ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos><start_of_turn>user\\nWrite a short story about a cat and a dog.<end_of_turn>\\n<start_of_turn>model\\nJasper, a sleek black cat with ice-blue<end_of_turn>\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e21e4419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 33, 2304])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eea61a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     2,      2,    106,   1645,    108,   5559,    476,   3309,   3904,\n",
       "          1105,    476,   4401,    578,    476,   5929, 235265,    107,    108,\n",
       "           106,   2516,    108, 123635, 235269,    476,  69392,   2656,   4401,\n",
       "           675,   8357, 235290,   8796,    107,    108])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6986c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a4c711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 435, 2560])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('/workspace/llm-progress-monitor/rollouts-test/activations/0.pt')[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbaa808e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.8400e+02,  4.9688e+00, -2.5125e+01,  ...,  7.1875e-01,\n",
       "           5.0938e+00,  1.6953e+00],\n",
       "         [ 3.5000e+01,  4.0625e+00, -7.2500e+00,  ..., -1.3086e-01,\n",
       "           2.1387e-01,  1.8262e-01],\n",
       "         [ 3.2250e+01,  3.8125e+00, -4.1250e+00,  ..., -7.4609e-01,\n",
       "          -1.9727e-01,  1.0645e-01],\n",
       "         ...,\n",
       "         [ 2.0250e+01,  3.2500e+00,  3.0312e+00,  ..., -2.3242e-01,\n",
       "           4.5508e-01, -5.2734e-02],\n",
       "         [ 1.5875e+01,  3.3594e+00,  1.5625e+00,  ...,  8.4961e-02,\n",
       "           9.7656e-02, -8.0078e-02],\n",
       "         [ 1.7875e+01,  4.1875e+00,  1.4609e+00,  ..., -1.9531e-03,\n",
       "           3.5938e-01, -3.9062e-02]]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('/workspace/llm-progress-monitor/rollouts-test/activations/1.pt')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f339a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_weights = torch.load('/workspace/llm-progress-monitor/rollouts-test/probe_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f935fac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 2560])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064dcfbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Convert to numpy for PCA\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m weights_np = \u001b[43mprobe_weights\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Fit PCA with 2 components\u001b[39;00m\n\u001b[32m      9\u001b[39m pca = PCA(n_components=\u001b[32m2\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Convert to numpy for PCA\n",
    "weights_np = probe_weights.cpu().detach().numpy()\n",
    "\n",
    "# Fit PCA with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "weights_pca = pca.fit_transform(weights_np)\n",
    "\n",
    "# Plot the weights in PCA space\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(weights_pca[:, 0], weights_pca[:, 1], alpha=0.7)\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.title('Probe Weights in PCA Space')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total variance explained by first 2 components: {pca.explained_variance_ratio_.sum():.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
